{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0aa5ea",
   "metadata": {},
   "source": [
    "# `S`um of `M`inimum of `C`onvex \n",
    "\n",
    "<b>author</b>: @guiguiom \n",
    "\n",
    "<b>package name</b>: SMC\n",
    "\n",
    "<b>package type</b>: [CVXPY](https://www.cvxpy.org) extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c7ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic imports \n",
    "import numbers\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.expressions.expression import Expression\n",
    "from cvxpy.expressions.constants import Constant\n",
    "from scipy.special import softmax\n",
    "import itertools\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210e876",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b490ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Mathieu Blondel\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "def proj_simplex_vec(V, z=1):\n",
    "    n_features = V.shape[1]\n",
    "    U = np.sort(V, axis=1)[:, ::-1]\n",
    "    z = np.ones(len(V)) * z\n",
    "    cssv = np.cumsum(U, axis=1) - z[:, np.newaxis]\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = U - cssv / ind > 0\n",
    "    rho = np.count_nonzero(cond, axis=1)\n",
    "    theta = cssv[np.arange(len(V)), rho - 1] / rho\n",
    "    return np.maximum(V - theta[:, np.newaxis], 0)\n",
    "\n",
    "def proj_simplex(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30fff4",
   "metadata": {},
   "source": [
    "### objective creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a07fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### \n",
    "### \n",
    "# new class\n",
    "### \n",
    "### \n",
    "### \n",
    "\n",
    "class MinExpr:\n",
    "    \"\"\"\n",
    "    class used to represent the minimum of cvxpy expressions \n",
    "    --------------------------------------------------------\n",
    "    \n",
    "    Attributes: \n",
    "    \n",
    "    expr_array : list or 2d-array of CONVEX cvxpy Expression \n",
    "        LIST\n",
    "        | every Expression must exhibit same dimension \n",
    "        | within each Expression, a single dtype is allowed\n",
    "    dim : int\n",
    "        | represents the \"depth\"/\"dimension\" of Expression objects stored in expr_array\n",
    "    NOTES:\n",
    "        \n",
    "        ARRAY entry at (pos1,pos2) <=> LIST element at (pos2) regarding dimension pos1\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls)\n",
    "\n",
    "    def __init__(self, expr_array):\n",
    "        self.expressions = None\n",
    "        if isinstance(expr_array,Expression): # array case\n",
    "            self.expressions = expr_array.copy()\n",
    "        elif isinstance(expr_array,list): # list case \n",
    "            try:\n",
    "                self.expressions = cp.vstack(expr_array.copy()).T\n",
    "                assert isinstance(self.expressions,Expression),'one argument passed does not match cvxpy Expression format'\n",
    "            except:\n",
    "                print(\"error while creating MinExpr object:: check dimensions of list content arguments\")\n",
    "        else:\n",
    "            print(\"expr_array should be either a cvxpy Expression array or a list of Expression of equivalent sizes\")\n",
    "\n",
    "        if len(self.expressions.shape)<2:\n",
    "            self.dim = 1\n",
    "        elif len(self.expressions.shape)==2:\n",
    "            self.dim = self.expressions.shape[0]\n",
    "            if self.dim==1: # flatten() equivalent\n",
    "                self.expressions = self.expressions[0]\n",
    "        else: \n",
    "            print(\"expr_array must be a 1 or 2 dimensional\")\n",
    "       \n",
    "        assert self.expressions.is_convex(), \"expr must be convex\"\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"evaluates min_l=1...n of Expr_l for each pos1\"\"\"\n",
    "        if self.dim==1:\n",
    "            return np.min(self.expressions.value)\n",
    "        else: \n",
    "            return np.min(self.expressions.value,1)\n",
    "        \n",
    "    @property\n",
    "    def extended_values(self):\n",
    "        \"\"\"evaluates every component\"\"\"\n",
    "        return self.expressions.value\n",
    "    \n",
    "    @property \n",
    "    def ns(self):\n",
    "        if self.dim==1:\n",
    "            return [int(np.prod(self.expressions.shape))]\n",
    "        return self.dim*[int(self.expressions.shape[1])]\n",
    "    \n",
    "    def __add__(self, e):\n",
    "        if isinstance(e, MinExpr):\n",
    "            return SumMinExpr(list_min_exprs=[self,e])\n",
    "        elif isinstance(e, SumMinExpr):\n",
    "            return e+self\n",
    "        elif isinstance(e, numbers.Number):\n",
    "            self.expressions += Constant(e)\n",
    "            return self\n",
    "        elif isinstance(e, Expression):\n",
    "            assert e.is_convex(),'e should be a cvxpy CONVEX Expression'\n",
    "            try:\n",
    "                self.expressions += e\n",
    "            except:\n",
    "                print('dimensions mismatch')\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(\"type %s not supported in __add__\" % type(e))\n",
    "            \n",
    "    __radd__ = __add__\n",
    "    \n",
    "    def __mul__(self, e):\n",
    "        \"\"\"multiplies the MinExpr to another object\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        e : numbers.Number or np.ndarray (POSITIVE)\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            if e is not a supported type.\n",
    "        Returns\n",
    "        -------\n",
    "        SumMinExpr\n",
    "        \"\"\"\n",
    "        assert isinstance(e, numbers.Number) or isinstance(e,np.ndarray) or instance(e,Constant),'e should be a scalar or an np.ndarray'\n",
    "        if (isinstance(e,Constant) and e.is_nonneg()):\n",
    "            try:\n",
    "                self.expressions = cp.multiply(e,self.expressions)\n",
    "            except:\n",
    "                raise ValueError('dimension not matching between e and self.expressions')\n",
    "            return self\n",
    "        elif np.min(e)>=0:\n",
    "            try:\n",
    "                self.expressions = cp.multiply(Constant(e),self.expressions)\n",
    "            except:\n",
    "                raise ValueError('dimension not matching between e and self.expressions')\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(\"type %s not supported in __add__\" % type(e))\n",
    "            \n",
    "    __rmul__ = __mul__ \n",
    "    \n",
    "    def clip(self,lamb):\n",
    "        \"\"\"takes the minimum between a MinExpr and a scalar lamb\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lamb : numbers.Number \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        MinExpr\n",
    "        \"\"\"\n",
    "        assert isinstance(lamb,numbers.Number),'lamb should be a number'\n",
    "        if self.dim>1:\n",
    "            self.expressions = cp.hstack((self.expressions,lamb*np.ones((self.dim,1))))\n",
    "        else:\n",
    "            self.expressions = cp.hstack((self.expressions,lamb))\n",
    "            \n",
    "    def compress(self,weights=None):\n",
    "        \"\"\"produces the cvxpy CONVEX Expression sum_l=1...ns weight_l*Expr_l\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        weights : None (default) or np.ndarray\n",
    "            | weights being positive and of length ns\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Expression \n",
    "        \"\"\"\n",
    "        loc_ns = self.ns[0]\n",
    "        if weights is None:\n",
    "            weights = np.ones(loc_ns)/loc_ns\n",
    "        if self.dim==1:\n",
    "            assert len(weights)==loc_ns and (np.array(weights)>=0).all(),'weights should be a positive vector of length ns'\n",
    "            sw_ = sum(weights)\n",
    "            return np.array(weights)/sw_@self.expressions\n",
    "        else:\n",
    "            assert weights.shape == (self.dim,loc_ns) and (np.array(weights)>=0).all(),'weights should be a positive matrix of size (self.dim,ns)'\n",
    "            sw_ = np.sum(weights,1)\n",
    "            return cp.sum(cp.multiply(np.array(weights)/np.outer(np.ones(self.dim),sw_),self.expressions))\n",
    "        \n",
    "        \n",
    "    def param_expand(self):\n",
    "        \"\"\"produces the parametric cvxpy CONVEX Expression sum_l=1...ns weight_l*Expr_l\n",
    "           with newly instanciated cvxpy POSITIVE parameters weight_l for l=1...ns\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Expression (parametric)\n",
    "        \"\"\"\n",
    "        new_param = cp.Parameter(self.expressions.shape,nonneg=True)\n",
    "        return cp.sum(cp.multiply(new_param,self.expressions)),[new_param]\n",
    "    \n",
    "### \n",
    "### \n",
    "### \n",
    "# new class\n",
    "### \n",
    "### \n",
    "### \n",
    "\n",
    "    \n",
    "class SumMinExpr:\n",
    "    \"\"\"\n",
    "    class used to represent a sum of MinExpr\n",
    "    ----------------------------------------\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "    main_expr: Expression\n",
    "        | CONVEX cvxpy Expression that stands outside Min operators (see doc.)\n",
    "        \n",
    "    Methods:\n",
    "\n",
    "    __add__(e)\n",
    "        -> adds the object to an Expression, MinExpr, SumOfMinExpr, or numbers.Number\n",
    "    \"\"\"\n",
    "    \n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls)\n",
    "\n",
    "    def __init__(self, list_min_exprs,main_fun=None):\n",
    "        if main_fun is not None:\n",
    "            assert isinstance(main_fun,Expression),'main (common) expression should be a cvxpy Expression'\n",
    "            assert main_fun.is_convex(),'main (common) expression should be convex'\n",
    "            self.main_expr = main_fun.copy()\n",
    "        else:\n",
    "            self.main_expr = Constant(0.0)\n",
    "        self.min_exprs = list_min_exprs\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def num_exprs(self):\n",
    "        'returns N in our formulation of SMC'\n",
    "        return sum([me.dim for me in self.min_exprs])\n",
    "    \n",
    "    @property\n",
    "    def ns_list(self):\n",
    "        buf = []\n",
    "        for me in self.min_exprs:\n",
    "            buf.append(me.ns)\n",
    "        return buf\n",
    "\n",
    "    def __add__(self, e):\n",
    "        \"\"\"adds the SumMinExpr to another object\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        e : Expression, MinExpr, SumMinExpr, or numbers.Number\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            if e is not a supported type.\n",
    "        Returns\n",
    "        -------\n",
    "        SumMinExpr\n",
    "        \"\"\"\n",
    "        if isinstance(e, MinExpr):\n",
    "            self.min_exprs += [e]\n",
    "            return self\n",
    "        elif isinstance(e, SumMinExpr):\n",
    "            self.min_exprs += e.min_exprs\n",
    "            self.main_expr += e.main_expr\n",
    "            return self\n",
    "        elif isinstance(e, numbers.Number):\n",
    "            self.main_expr += Constant(e)\n",
    "            return self\n",
    "        elif isinstance(e, Expression):\n",
    "            assert e.is_convex(),'e should be a cvxpy CONVEX Expression'\n",
    "            self.main_expr += e\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(\"type %s not supported in __add__\" % type(e))\n",
    "            \n",
    "    __radd__ = __add__\n",
    "    \n",
    "    \n",
    "    def __mul__(self, e):\n",
    "        try:\n",
    "            self.main_expr *= Constant(e)\n",
    "            for me in self.min_exprs:\n",
    "                me *= e\n",
    "        except:\n",
    "            raise ValueError('dimension not matching between e and either self.main_expr or one of the expr')\n",
    "        return self\n",
    "            \n",
    "    __rmul__ = __mul__\n",
    "\n",
    "    \n",
    "    def clip(self, lamb):\n",
    "        \"\"\"clips every term of a SumMinExpr to scalar value lamb\n",
    "        \"\"\"\n",
    "        assert isinstance(lamb,numbers.Number),'lamb should be a number'\n",
    "        for me in self.min_exprs:\n",
    "            me.clip(lamb)\n",
    "    \n",
    "    @property \n",
    "    def value(self):\n",
    "        \"\"\"overall value\"\"\"\n",
    "        return self.main_expr.value + np.sum([me.value for me in self.min_exprs])\n",
    "    \n",
    "    @property\n",
    "    def extended_values(self):\n",
    "        return [me.extended_values for me in self.min_exprs]\n",
    "    \n",
    "    def compress(self,weights_list):\n",
    "        comp = self.main_expr\n",
    "        assert len(weights_list)==self.num_exprs,'there should be as many weighting factors as MinExpr stored in SumMinExpr object'\n",
    "        for me,weights in zip(self.min_exprs,weights_list):\n",
    "            comp += me.compress(weights)\n",
    "        return comp\n",
    "    \n",
    "    def param_expand(self):\n",
    "        comp = self.main_expr\n",
    "        new_param_list = []\n",
    "        for me in self.min_exprs:\n",
    "            new_term,new_param = me.param_expand()\n",
    "            comp += new_term\n",
    "            new_param_list += new_param\n",
    "        return comp,new_param_list\n",
    "    \n",
    "    # TO DO .visualize(variable_values)\n",
    "    \n",
    "### \n",
    "### \n",
    "### \n",
    "# static method\n",
    "### \n",
    "### \n",
    "### \n",
    "def minimum(e,lamb):\n",
    "    assert isinstance(lamb,numbers.Number),'lamb should be a number'\n",
    "    assert isinstance(e, Expression),'e should be a cvxpy Expression'\n",
    "    if len(e.shape)<2:\n",
    "        return SumMinExpr([MinExpr(cp.hstack((cp.reshape(e,(e.shape[0],1)),lamb*np.ones((e.shape[0],1)))))])\n",
    "    else:\n",
    "        return SumMinExpr([MinExpr(cp.hstack((e,lamb*np.ones((e.shape[0],1)))))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0000b6",
   "metadata": {},
   "source": [
    "### Problem Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f488b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "    \"\"\"\n",
    "    minimizing a SumMinExpr\n",
    "    --------------------------------------------\n",
    "    \n",
    "    Attributes:\n",
    "\n",
    "    objective : SumMinExpr\n",
    "    constraints : list\n",
    "        | list of cvxpy constraints\n",
    "    vars_ : list\n",
    "        | cvxpy Variables (pointers) involved in the problem\n",
    "    custom_param_expand : \n",
    "        | @comment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, objective, constraints=[],custom_param_expand=None):\n",
    "        if isinstance(objective, SumMinExpr):\n",
    "            self.objective = objective\n",
    "        elif isinstance(objective,cp.Minimize):\n",
    "            assert objective.is_dcp(),'objective should be DCP'\n",
    "            self.objective = SumMinExpr(list_min_exprs=[],main_fun=objective.expr)\n",
    "        elif isinstance(objective,cp.Maximize):\n",
    "            assert objective.is_dcp(),'objective should be DCP'\n",
    "            self.objective = SumMinExpr(list_min_exprs=[],main_fun=-objective.expr)\n",
    "        else:\n",
    "            raise ValueError('objective should either be a valid cvxpy DCP Objective or SumMinExpr')\n",
    "        self.constraints = constraints\n",
    "        for cstr in self.constraints:\n",
    "            assert cstr.is_dcp(),'constraints must be CONVEX'\n",
    "        self.vars_ = []\n",
    "        for min_expr in self.objective.min_exprs:\n",
    "            self.vars_ += min_expr.expressions.variables()\n",
    "        self.vars_ += self.objective.main_expr.variables()\n",
    "        for constr in self.constraints:\n",
    "            self.vars_ += constr.variables()\n",
    "        self.vars_ = list(set(self.vars_))\n",
    "        if custom_param_expand is None:\n",
    "            self.custom_set = False\n",
    "            self.param_obj_fun,self.param_pointers_list = self.objective.param_expand()\n",
    "        else:\n",
    "            self.custom_set = True\n",
    "            self.param_obj_fun,self.param_pointers_list,self.w2p = custom_param_expand[0],custom_param_expand[1],custom_param_expand[2]\n",
    "\n",
    "\n",
    "    def solve(self, method=\"boyd\", *args, **kwargs):\n",
    "        \"\"\"approximately solve the problem \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        method : str\n",
    "            | 'boyd','vandessel'\n",
    "        args, kwargs\n",
    "        \"\"\"\n",
    "        if method == \"boyd\":\n",
    "            return self._solve_GSAM(*args, **kwargs)\n",
    "        elif method == \"vandessel\":\n",
    "            return self._solve_ASAAM(*args, **kwargs)\n",
    "        elif method == \"am\":\n",
    "            return self._solve_AM(*args, **kwargs)\n",
    "        raise NotImplementedError(f\"method {method} not supported\")\n",
    "        \n",
    "        \n",
    "    def weights_setup(self,mode='equiv'):\n",
    "        weights = []\n",
    "        if mode=='equiv':\n",
    "            for num_s in self.objective.ns_list:\n",
    "                if len(num_s)==1:\n",
    "                    weights.append(np.ones(num_s[0])/num_s[0])\n",
    "                else:\n",
    "                    weights.append(np.outer(np.ones(len(num_s)),np.ones(num_s[0])/num_s[0]))\n",
    "        elif mode=='random':\n",
    "            for num_s in self.objective.ns_list:\n",
    "                if len(num_s)==1:\n",
    "                    base_weight = np.random.uniform(0,1,num_s[0])\n",
    "                    weights.append(base_weight/sum(base_weight))\n",
    "                else:\n",
    "                    base_weight = np.random.uniform(0,1,(len(num_s),num_s[0]))\n",
    "                    weights.append(base_weight/np.outer(np.sum(base_weight,1),np.ones(num_s[0])))   \n",
    "        return weights\n",
    "        \n",
    "        \n",
    "    def _solve_GSAM(self,stepsize=0.2, maxIters=50, verb_=False,extra_verb_=False,\n",
    "                warm_start=False, warm_start_weights=None,init_weights='equiv',tol=1e-9, **kwargs):\n",
    "        \"\"\" (generalized signed Alternating Minimization)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        stepsize : double\n",
    "            | stepsize\n",
    "        maxIters : int\n",
    "            | maximum number of iterations (default = 50)\n",
    "        tol : double\n",
    "            | numerical tolerance for stopping condition (default = 1e-9)\n",
    "        verb_ : bool\n",
    "            | whether or not to print information (default = False)\n",
    "        warm_start : bool\n",
    "            | whether or not some value affectation has already been conducted on Problem's variables vars_\n",
    "        warm_start_weights : np.ndarray\n",
    "            | choice bias; warm start value for a priori weights (default = None)\n",
    "        init_weights : str or callable\n",
    "            | 'random','equiv' or homemade init technique\n",
    "        **kwargs\n",
    "            | keyword arguments to be sent to cvxpy solve() function\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        info : dict\n",
    "            | dictionary of solver information\n",
    "        \"\"\"\n",
    "        if warm_start_weights is not None:\n",
    "            weights = warm_start_weights.copy()\n",
    "        else:\n",
    "            if isinstance(init_weights,str):\n",
    "                weights = self.weights_setup(mode=init_weights)\n",
    "            else:\n",
    "                try:\n",
    "                    weights = init_weights(self)\n",
    "                    # TO DO full assertive statements \n",
    "                    assert len(weights)==self.objective.num_exprs,'user prescribed weights should match objective SumMinExpr.num_exprs'\n",
    "                    for elem in weights:\n",
    "                        if len(elem.shape)==1:\n",
    "                            assert np.min(elem)>=-1e-8 and abs(1-np.sum(elem))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        elif len(elem.shape)==2:\n",
    "                            assert np.min(elem)>=-1e-8 and np.max(np.abs(1-np.sum(elem,1)))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        else:\n",
    "                            raise ValueError('tensor like parameters not accepted yet...')\n",
    "                except:\n",
    "                    print('init_weights as a callable should take a smc.Problem argument | equiv. weights loaded...')\n",
    "                    weights = self.weights_setup()\n",
    "        \n",
    "        cvx_param_obj_prob = cp.Problem(cp.Minimize(self.param_obj_fun), self.constraints)\n",
    "        \n",
    "        out_val = []\n",
    "        \n",
    "        last_val = np.inf\n",
    "        decr = np.inf\n",
    "            \n",
    "        for k in range(maxIters):\n",
    "            # x step, skipped if warm_start=True and k=0\n",
    "            if not warm_start or k > 0:\n",
    "                ## param affectation\n",
    "                if self.custom_set:\n",
    "                    params = self.w2p(weights)\n",
    "                    for param,param_pointer in zip(params,self.param_pointers_list):\n",
    "                        param_pointer.value = param\n",
    "                else:\n",
    "                    for weight,param_pointer in zip(weights,self.param_pointers_list):\n",
    "                        param_pointer.value = weight # copy ?\n",
    "                cvx_param_obj_prob.solve(**kwargs)\n",
    "                prob_value = cvx_param_obj_prob.value\n",
    "                decr = max(0.0,last_val-prob_value)\n",
    "                if cvx_param_obj_prob.status in ['unbounded','infeasible']:\n",
    "                    raise ValueError(\"weights-fixed problem is %s.\" % cvx_param_obj_prob.status)\n",
    "\n",
    "            # weights step\n",
    "            vals_list = self.objective.extended_values\n",
    "            div_linf = -np.inf\n",
    "            new_weights = []\n",
    "            for weight,vals in zip(weights,vals_list):\n",
    "                if len(vals.shape)<2:\n",
    "                    minid = np.argmin(vals)\n",
    "                    gbar = np.array(vals)-vals[minid]\n",
    "                    sgbar = np.sign(gbar)\n",
    "                    wcand = weight-stepsize*sgbar/(len(gbar)-1)\n",
    "                    wcand[minid] += stepsize*(1+sgbar[minid]/(len(gbar)-1)) \n",
    "                    wcand = proj_simplex(wcand)\n",
    "                elif len(vals.shape)==2:\n",
    "                    minids = np.argmin(vals,1)\n",
    "                    gbar = np.array(vals)-np.outer(np.min(vals,1),np.ones(vals.shape[1]))\n",
    "                    sgbar = np.sign(gbar)\n",
    "                    wcand = weight-stepsize*np.sign(gbar)/(len(gbar[0])-1)\n",
    "                    for _,mid in enumerate(minids):\n",
    "                        wcand[_,mid] += stepsize*(1+sgbar[_,mid]/(len(gbar[0])-1))\n",
    "                    wcand = proj_simplex_vec(wcand)\n",
    "                else:\n",
    "                    print('ValueError: wrong evaluation of component functions... please check dimensions')\n",
    "                div_linf = max(div_linf,np.max(np.abs(wcand-weight)))\n",
    "                new_weights.append(wcand)\n",
    "                \n",
    "            last_val = prob_value\n",
    "            true_val = self.objective.value\n",
    "            out_val.append(true_val)\n",
    "\n",
    "            if verb_:\n",
    "                print(\"iter. %04d | Fval. %4.4e | BICval. %4.4e \" % (k + 1, true_val,prob_value))\n",
    "                if extra_verb_:\n",
    "                    print('used weights: '+str(weights))\n",
    "                    print('variables: '+str([var.value for var in self.vars_]))\n",
    "                \n",
    "            if decr < tol and k>3:\n",
    "                if verb_:\n",
    "                    print (\"-> terminated (stopping condition satisfied)\")\n",
    "                break\n",
    "            else:\n",
    "                weights = new_weights.copy()\n",
    "                \n",
    "        if verb_ and k == maxIters-1:\n",
    "            print (\"-> terminated (maximum number of iterations reached)\")\n",
    "            \n",
    "        return {'iters':k+1,'stopping_condition':decr,'objective_values':out_val}\n",
    "    \n",
    "\n",
    "    def _solve_AM(self,maxIters=50,verb_=False,extra_verb_=False,tol=1e-9,\n",
    "                warm_start=False, warm_start_weights=None,init_weights='equiv', **kwargs):\n",
    "        \"\"\" (Alternating Minimization)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        stepsize : double\n",
    "            | stepsize\n",
    "        maxIters : int\n",
    "            | maximum number of iterations (default = 50)\n",
    "        tol : double\n",
    "            | numerical tolerance for stopping condition (default = 1e-9)\n",
    "        verb_ : bool\n",
    "            | whether or not to print information (default = False)\n",
    "        warm_start : bool\n",
    "            | whether or not some value affectation has already been conducted on Problem's variables vars_\n",
    "        warm_start_weights : np.ndarray\n",
    "            | choice bias; warm start value for a priori weights (default = None)\n",
    "        init_weights : str or callable\n",
    "            | 'random','equiv' or homemade init technique\n",
    "        **kwargs\n",
    "            | keyword arguments to be sent to cvxpy solve() function\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        info : dict\n",
    "            | dictionary of solver information\n",
    "        \"\"\"\n",
    "        if warm_start_weights is not None:\n",
    "            weights = warm_start_weights.copy()\n",
    "        else:\n",
    "            if isinstance(init_weights,str):\n",
    "                weights = self.weights_setup(mode=init_weights)\n",
    "            else:\n",
    "                try:\n",
    "                    weights = init_weights(self)\n",
    "                    # TO DO full assertive statements \n",
    "                    assert len(weights)==self.objective.num_exprs,'user prescribed weights should match objective SumMinExpr.num_exprs'\n",
    "                    for elem in weights:\n",
    "                        if len(elem.shape)==1:\n",
    "                            assert np.min(elem)>=-1e-8 and abs(1-np.sum(elem))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        elif len(elem.shape)==2:\n",
    "                            assert np.min(elem)>=-1e-8 and np.max(np.abs(1-np.sum(elem,1)))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        else:\n",
    "                            raise ValueError('tensor like parameters not accepted yet...')\n",
    "                except:\n",
    "                    print('init_weights as a callable should take a smc.Problem argument | equiv. weights loaded...')\n",
    "                    weights = self.weights_setup()\n",
    "        \n",
    "        cvx_param_obj_prob = cp.Problem(cp.Minimize(self.param_obj_fun), self.constraints)\n",
    "        \n",
    "        out_val = []\n",
    "        \n",
    "        last_val = np.inf\n",
    "        decr = np.inf\n",
    "            \n",
    "        for k in range(maxIters):\n",
    "            # x step, skipped if warm_start=True and k=0\n",
    "            if not warm_start or k > 0:\n",
    "                ## param affectation\n",
    "                if self.custom_set:\n",
    "                    params = self.w2p(weights)\n",
    "                    for param,param_pointer in zip(params,self.param_pointers_list):\n",
    "                        param_pointer.value = param\n",
    "                else:\n",
    "                    for weight,param_pointer in zip(weights,self.param_pointers_list):\n",
    "                        param_pointer.value = weight # copy ?\n",
    "                cvx_param_obj_prob.solve(**kwargs)\n",
    "                prob_value = cvx_param_obj_prob.value\n",
    "                decr = max(0.0,last_val-prob_value)\n",
    "                if cvx_param_obj_prob.status in ['unbounded','infeasible']:\n",
    "                    raise ValueError(\"weights-fixed problem is %s.\" % cvx_param_obj_prob.status)\n",
    "\n",
    "            # weights step\n",
    "            vals_list = self.objective.extended_values\n",
    "            new_weights = []\n",
    "            for weight,vals in zip(weights,vals_list):\n",
    "                if len(vals.shape)<2:\n",
    "                    wcand = np.zeros(vals.shape)\n",
    "                    wcand[np.argmin(vals)] += 1\n",
    "                elif len(vals.shape)==2:\n",
    "                    wcand = np.zeros(vals.shape)\n",
    "                    minids = np.argmin(vals,1)\n",
    "                    for _,mid in enumerate(minids):\n",
    "                        wcand[_,mid] += 1\n",
    "                else:\n",
    "                    print('ValueError: wrong evaluation of component functions... please check dimensions')\n",
    "                new_weights.append(wcand)\n",
    "                    \n",
    "            last_val = prob_value\n",
    "            true_val = self.objective.value\n",
    "            out_val.append(true_val)\n",
    "\n",
    "            if verb_:\n",
    "                print(\"iter. %04d | Fval. %4.4e | BICval. %4.4e | \" % (k + 1, true_val,prob_value))\n",
    "                if extra_verb_:\n",
    "                    print('used weights: '+str(weights))\n",
    "                    print('variables: '+str([var.value for var in self.vars_]))\n",
    "                \n",
    "            if decr < tol and k>3:\n",
    "                if verb_:\n",
    "                    print (\"-> terminated (stopping condition satisfied)\")\n",
    "                break\n",
    "            else:\n",
    "                weights = new_weights.copy()\n",
    "                \n",
    "        if verb_ and k == maxIters-1:\n",
    "            print (\"-> terminated (maximum number of iterations reached)\")\n",
    "            \n",
    "        return {'iters':k+1,'stopping_condition':decr,'objective_values':out_val}\n",
    "    \n",
    "\n",
    "    \n",
    "    def _solve_ASAAM(self,maxIters=50, tol=1e-9, verb_=False,extra_verb_=False,warm_start_weights=None,init_weights='equiv',\\\n",
    "                     min_decr = 1e-5,scale_up=3/2,scale_down=2, **kwargs):\n",
    "        \"\"\" (adaptive simulated annealing Alternating Minimization)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        schedule_constant : double\n",
    "            | ...\n",
    "        burnin : int\n",
    "            | burnin phase length;\n",
    "        maxIters : int\n",
    "            | maximum number of iterations (default = 50)\n",
    "        tol : double\n",
    "            | numerical tolerance for stopping condition (default = 1e-9)\n",
    "        verb_ : bool\n",
    "            | whether or not to print information (default = False)\n",
    "        warm_start_weights : np.ndarray\n",
    "            | choice bias; warm start value for a priori weights (default = None)\n",
    "        init_weights : str or callable\n",
    "            | 'random','equiv' or homemade init technique\n",
    "        **kwargs\n",
    "            | keyword arguments to be sent to cvxpy solve() function\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        info : dict\n",
    "            | dictionary of solver information\n",
    "        \"\"\"\n",
    "        if warm_start_weights is not None:\n",
    "            weights = warm_start_weights.copy()\n",
    "        else:\n",
    "            if isinstance(init_weights,str):\n",
    "                weights = self.weights_setup(mode=init_weights)\n",
    "            else:\n",
    "                try:\n",
    "                    weights = init_weights(self)\n",
    "                    # TO DO full assertive statements \n",
    "                    assert len(weights)==self.objective.num_exprs,'user prescribed weights should match objective SumMinExpr.num_exprs'\n",
    "                    for elem in weights:\n",
    "                        if len(elem.shape)==1:\n",
    "                            assert np.min(elem)>=-1e-8 and abs(1-np.sum(elem))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        elif len(elem.shape)==2:\n",
    "                            assert np.min(elem)>=-1e-8 and np.max(np.abs(1-np.sum(elem,1)))<=1e-8,'every weight vector should be POSITIVE and sum up to 1'\n",
    "                        else:\n",
    "                            raise ValueError('tensor like parameters not accepted yet...')\n",
    "                except:\n",
    "                    print('init_weights as a callable should take a smc.Problem argument | equiv. weights loaded...')\n",
    "                    weights = self.weights_setup()\n",
    "                    \n",
    "        # line-serach built-up \n",
    "        temp,maxtemp,mintemp = -1.0,-1.0,-(2**15)\n",
    "        \n",
    "        cvx_param_obj_prob = cp.Problem(cp.Minimize(self.param_obj_fun), self.constraints)\n",
    "        \n",
    "        out_val = []\n",
    "        \n",
    "        last_val = np.inf\n",
    "            \n",
    "        for k in range(maxIters):\n",
    "            \n",
    "            decr = 0.0\n",
    "            \n",
    "            if k>0:\n",
    "                vals_list = self.objective.extended_values\n",
    "                base_cands = []\n",
    "                weights = []\n",
    "\n",
    "                # weights step -> temp>-np.inf\n",
    "                for vals in vals_list:\n",
    "                    if len(vals.shape)==1:\n",
    "                        meanval = np.mean(vals)\n",
    "                        wcand = (vals-meanval)/np.maximum(1,np.abs(meanval))\n",
    "                        base_cands.append(wcand)\n",
    "                        if temp>-np.inf:\n",
    "                            weights.append(softmax(wcand*temp))\n",
    "                        else:\n",
    "                            buf = np.zeros(wcand.shape)\n",
    "                            buf[np.argmin(wcand)]+=1\n",
    "                            weights.append(buf)\n",
    "                    elif len(vals.shape)==2:\n",
    "                        meanval = np.mean(vals,1)\n",
    "                        matmean = np.outer(meanval,np.ones(vals.shape[1]))\n",
    "                        wcand = (vals-matmean)/np.maximum(1,np.abs(matmean))\n",
    "                        base_cands.append(wcand)\n",
    "                        if temp>-np.inf:\n",
    "                            weights.append(softmax(wcand*temp,axis=1))\n",
    "                        else:\n",
    "                            buf = np.zeros(wcand.shape)\n",
    "                            minids = np.argmin(wcand,1)\n",
    "                            for _,mid in enumerate(minids):\n",
    "                                buf[_,mid] +=1\n",
    "                            weights.append(buf)\n",
    "                    else:\n",
    "                        print('ValueError: wrong evaluation of component functions... please check dimensions')\n",
    "                        return {'iters':k+1,'stopping_condition':None,'objective_values':out_val}\n",
    "                    \n",
    "            \n",
    "            condition = True\n",
    "            while condition:\n",
    "                \n",
    "                # x step\n",
    "                ## param affectation\n",
    "                if self.custom_set:\n",
    "                    params = self.w2p(weights)\n",
    "                    for param,param_pointer in zip(params,self.param_pointers_list):\n",
    "                        param_pointer.value = param\n",
    "                else:\n",
    "                    for weight,param_pointer in zip(weights,self.param_pointers_list):\n",
    "                        param_pointer.value = weight # copy ?\n",
    "                cvx_param_obj_prob.solve(**kwargs)\n",
    "                prob_value = cvx_param_obj_prob.value\n",
    "                decr = max(0.0,last_val-prob_value)\n",
    "                if cvx_param_obj_prob.status in ['unbounded','infeasible']:\n",
    "                    raise ValueError(\"weights-fixed problem is %s.\" % cvx_param_obj_prob.status)\n",
    "                    \n",
    "                    \n",
    "                condition = decr<min_decr and temp>-np.inf\n",
    "\n",
    "                # check decrease\n",
    "                if decr>=min_decr:\n",
    "                    printemp=temp\n",
    "                    if temp==-np.inf:\n",
    "                        temp = mintemp # @check\n",
    "                    else:\n",
    "                        temp = min(maxtemp,temp/scale_up)\n",
    "                    last_val = prob_value\n",
    "                elif temp>-np.inf:\n",
    "                    temp = temp*scale_down\n",
    "                    if temp<mintemp:\n",
    "                        temp = -np.inf\n",
    "                    if extra_verb_:\n",
    "                        print('backtracking...freezing more | temp = '+str(temp))\n",
    "                    weights = []\n",
    "                    for wcand in base_cands:\n",
    "                        if len(wcand.shape)==1:\n",
    "                            if temp>-np.inf:\n",
    "                                weights.append(softmax(wcand*temp))\n",
    "                            else:                    \n",
    "                                buf = np.zeros(wcand.shape)\n",
    "                                buf[np.argmin(wcand)] += 1\n",
    "                                weights.append(buf)\n",
    "                        elif len(wcand.shape)==2:\n",
    "                            if temp>-np.inf:\n",
    "                                weights.append(softmax(wcand*temp,axis=1))\n",
    "                            else:\n",
    "                                buf = np.zeros(wcand.shape)\n",
    "                                minids = np.argmin(wcand,1)\n",
    "                                for _,mid in enumerate(minids):\n",
    "                                    buf[_,mid] += 1\n",
    "                                weights.append(buf)\n",
    "                        else:\n",
    "                            print('ValueError: wrong evaluation of component functions... please check dimensions')\n",
    "                            return {'iters':k+1,'stopping_condition':decr,'objective_values':out_val}\n",
    "                    \n",
    "            true_val = self.objective.value\n",
    "            out_val.append(true_val)\n",
    "\n",
    "            if verb_:\n",
    "                print(\"iter. %04d | Fval. %4.4e | BICval. %4.4e | decr. %4.4e | temp. %4.4e\" % (k + 1, true_val,prob_value, decr,printemp))\n",
    "                if extra_verb_:\n",
    "                    print('used weights: '+str(weights))\n",
    "                    print('variables: '+str([var.value for var in self.vars_]))\n",
    "                \n",
    "            if (decr < tol and k>3) or temp<=-np.inf:\n",
    "                if verb_:\n",
    "                    print (\"-> terminated (stopping condition satisfied)\")\n",
    "                break\n",
    "                \n",
    "        if verb_ and k == maxIters-1:\n",
    "            print (\"-> terminated (maximum number of iterations reached)\")\n",
    "            \n",
    "        return {'iters':k+1,'stopping_condition':decr,'objective_values':out_val}\n",
    "    \n",
    "    \n",
    "    @property \n",
    "    def value(self):\n",
    "        for cstr in self.constraints:\n",
    "            if cstr.value()==False:\n",
    "                return np.inf # infeasibility\n",
    "        return self.objective.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c59b8",
   "metadata": {},
   "source": [
    "### Specific WARM-STARTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
