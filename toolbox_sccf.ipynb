{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51207fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.expressions.expression import Expression\n",
    "from cvxpy.expressions.constants import Constant\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b, check_grad\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "def asscalar(x):\n",
    "    if isinstance(x, numbers.Number):\n",
    "        return x\n",
    "    else:\n",
    "        return x.item() \n",
    "\n",
    "def flatten_vars(vars):\n",
    "    x = np.empty(0)\n",
    "    for v in vars:\n",
    "        x = np.append(x, v.value.flatten(order=\"F\"))\n",
    "    return x\n",
    "\n",
    "def unflatten_vars(x, vars):\n",
    "    i = 0\n",
    "    for v in vars:\n",
    "        num = int(np.prod(v.shape))\n",
    "        v.value = x[i:i+num].reshape(v.shape, order=\"F\")\n",
    "        i += num\n",
    "\n",
    "def flatten_grads(grads, vars):\n",
    "    grad = np.empty(0)\n",
    "    for v in vars:\n",
    "        try:\n",
    "            grad_v = grads[v]\n",
    "        except KeyError:\n",
    "            grad_v = np.zeros(v.shape)\n",
    "        if issparse(grad_v):\n",
    "            grad_v = grad_v.todense()\n",
    "        grad = np.append(grad, grad_v.flatten(order=\"F\"))\n",
    "    return grad\n",
    "\n",
    "\n",
    "class MinExpression:\n",
    "    \"\"\"\n",
    "    A class used to represent the minimum of a cvxpy expression and a number.\n",
    "    Attributes\n",
    "    ----------\n",
    "    expr : cvxpy Expression\n",
    "    a : numbers.Number\n",
    "    value : double\n",
    "        The evaluation of the expression\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, expr, a):\n",
    "        \"\"\"Forms the MinExpression min(expr, a).\n",
    "        Parameters\n",
    "        ----------\n",
    "        expr : cvxpy Expression\n",
    "        a : numbers.Number\n",
    "        \"\"\"\n",
    "        if isinstance(expr, numbers.Number):\n",
    "            expr = Constant(expr)\n",
    "        assert isinstance(expr, Expression), \"expr must be a cvxpy Expression\"\n",
    "        assert isinstance(a, numbers.Number), \"a must be a number\"\n",
    "        assert expr.is_convex(), \"expr must be convex\"\n",
    "        self.expr = expr\n",
    "        self.a = a\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"Evaluates min(expr, a).\"\"\"\n",
    "        return asscalar(min(self.expr.value, self.a))\n",
    "\n",
    "\n",
    "class SumOfMinExpressions:\n",
    "    \"\"\"\n",
    "    A class used to represent a sum of MinExpressions.\n",
    "    Attributes\n",
    "    ----------\n",
    "    min_exprs : list\n",
    "        List of MinExpression's.\n",
    "    value : double\n",
    "        The numerical evaluation of the object.\n",
    "    Methods\n",
    "    -------\n",
    "    __add__(e)\n",
    "        Adds the object to an Expression, MinExpression, SumOfMinExpressions, or numbers.Number\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_exprs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        min_exprs : list\n",
    "            The list of MinExpression's.\n",
    "        \"\"\"\n",
    "        self.min_exprs = min_exprs\n",
    "    \n",
    "    @property\n",
    "    def num_exprs(self):\n",
    "        return len(self.min_exprs)\n",
    "\n",
    "    def __add__(self, e):\n",
    "        \"\"\"Adds the SumOfMinExpressions to another object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        e : Expression, MinExpression, SumOfMinExpressions, or numbers.Number\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If e is not a supported type.\n",
    "        Returns\n",
    "        -------\n",
    "        expression : SumOfMinExpressions\n",
    "            The result of the addition.\n",
    "        \"\"\"\n",
    "        if isinstance(e, MinExpression):\n",
    "            self.min_exprs += [e]\n",
    "            return self\n",
    "        elif isinstance(e, SumOfMinExpressions):\n",
    "            self.min_exprs += e.min_exprs\n",
    "            return self\n",
    "        elif isinstance(e, numbers.Number):\n",
    "            self.min_exprs += minimum(e, e).min_exprs\n",
    "            return self\n",
    "        elif isinstance(e, Expression):\n",
    "            self.min_exprs += minimum(e, float(\"inf\")).min_exprs\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(\"type %s not supported in __add__\" % type(e))\n",
    "    \n",
    "    __radd__ = __add__\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"The value of the expression.\"\"\"\n",
    "        return asscalar(np.sum([min_expr.value for min_expr in self.min_exprs]))\n",
    "\n",
    "\n",
    "def minimum(expr, a):\n",
    "    \"\"\"Forms a SumOfMinExpressions object that represents min(expr, a).\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    expr : cvxpy Expression\n",
    "    a : numbers.Number\n",
    "    \"\"\"\n",
    "    return SumOfMinExpressions([MinExpression(expr, a)])\n",
    "\n",
    "\n",
    "class Problem:\n",
    "    \"\"\"\n",
    "    A class used to represent a problem of\n",
    "    minimizing a sum of clipped convex functions.\n",
    "    Attributes\n",
    "    ----------\n",
    "    objective : SumOfMinExpressions\n",
    "        The objective, which must be a SumOfMinExpressions.\n",
    "    constraints : list\n",
    "        A list of cvxpy constraints.\n",
    "    vars_ : list\n",
    "        The cvxpy Variables involved in the problem.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, objective, constraints=[]):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        objective : SumOfMinExpressions\n",
    "        constraints : list\n",
    "        \"\"\"\n",
    "        assert isinstance(objective, SumOfMinExpressions), \"objective must be a SumOfMinExpressions\"\n",
    "        self.objective = objective\n",
    "        self.constraints = constraints\n",
    "        self.vars_ = []\n",
    "        for min_expr in self.objective.min_exprs:\n",
    "            self.vars_ += min_expr.expr.variables()\n",
    "        for constr in self.constraints:\n",
    "            self.vars_ += constr.variables()\n",
    "        self.vars_ = list(set(self.vars_))\n",
    "\n",
    "    def solve(self, method=\"alternating\", *args, **kwargs):\n",
    "        \"\"\"Approximately solve the problem using convex-concave or L-BFGS.\n",
    "        Parameters\n",
    "        ==========\n",
    "        method : str\n",
    "            cvx_ccv, alternating, or lbfgs\n",
    "        args, kwargs\n",
    "        \"\"\"\n",
    "        if method == \"alternating\":\n",
    "            return self._solve_alternating(*args, **kwargs)\n",
    "        elif method == \"cvx_ccv\":\n",
    "            return self._solve_cvx_ccv(*args, **kwargs)\n",
    "        elif method == \"lbfgs\":\n",
    "            if len(self.constraints) > 0:\n",
    "                raise ValueError(\"Cannot use L-BFGS when there are constraints. Please use cvx_ccv or alternating\")\n",
    "            else:\n",
    "                return self._solve_lbfgs(*args, **kwargs)\n",
    "        \n",
    "        raise NotImplementedError(f\"method {method} not supported\")\n",
    "\n",
    "    def _solve_alternating(self, step_size=0.2, maxiter=50, tol=1e-9, verbose=False,\n",
    "                warm_start=False, warm_start_lam=None, **kwargs):\n",
    "        \"\"\"Approximately solves the Problem using an alternating minimization procedure.\n",
    "        Parameters\n",
    "        ----------\n",
    "        step_size : double\n",
    "            Step size\n",
    "        maxiter : int\n",
    "            Maximum number of iterations (default = 10)\n",
    "        tol : double\n",
    "            Numerical tolerance for stopping condition (default = 1e-5)\n",
    "        verbose : bool\n",
    "            Whether or not to print information (default = False)\n",
    "        warm_start : bool\n",
    "            Whether or not to warm start x (default = False)\n",
    "        warm_start_lam : np.array\n",
    "            Warm start value for lam (default = None)\n",
    "        **kwargs\n",
    "            Keyword arguments to be sent to cvxpy solve function\n",
    "        Returns\n",
    "        -------\n",
    "        info : dict\n",
    "            Dictionary of solver information\n",
    "        \"\"\"\n",
    "        m = self.objective.num_exprs\n",
    "        lam = 0.5 * np.ones(m)\n",
    "        if warm_start_lam is not None:\n",
    "            lam = warm_start_lam\n",
    "            \n",
    "        alphas = np.array([min_expr.a for min_expr in self.objective.min_exprs])\n",
    "        Ls, lams = [], []\n",
    "\n",
    "        lam_cp = cp.Parameter(m, nonneg=True)\n",
    "        objective = 0.0\n",
    "        for i, min_expr in enumerate(self.objective.min_exprs):\n",
    "            if min_expr.a == np.inf:\n",
    "                objective += min_expr.expr\n",
    "            else:\n",
    "                objective += lam_cp[i] * min_expr.expr\n",
    "                objective += (1 - lam_cp[i]) * min_expr.a\n",
    "        prob = cp.Problem(cp.Minimize(objective), self.constraints)\n",
    "        \n",
    "\n",
    "        for k in range(maxiter):\n",
    "            # x step, skip if warm_start=True and k=0\n",
    "            if not warm_start or k > 0:\n",
    "                lam_cp.value = lam\n",
    "                result = prob.solve(**kwargs)\n",
    "                if prob.status == 'unbounded' or prob.status == 'infeasible':\n",
    "                    raise ValueError(\"Un-clipped problem is %s.\" % prob.status)\n",
    "\n",
    "            # lam step\n",
    "            lams.append(lam)\n",
    "            fk = np.array([min_expr.expr.value for min_expr in self.objective.min_exprs])\n",
    "            lam_next = lam - step_size * np.sign(fk - alphas)\n",
    "            lam_next[alphas == np.inf] = 1.0\n",
    "            lam_next = np.clip(lam_next, 0.0, 1.0)\n",
    "\n",
    "            stopping_condition = np.linalg.norm(lam_next - lam, np.inf)\n",
    "\n",
    "            lam = lam_next.astype(np.double)\n",
    "            L = self.objective.value\n",
    "            Ls.append(L)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"%04d | %4.4e | %4.4e\" % (k + 1, L, stopping_condition))\n",
    "\n",
    "            if stopping_condition < tol:\n",
    "                if verbose:\n",
    "                    print (\"Terminated (stopping condition satisfied).\")\n",
    "                break\n",
    "                \n",
    "        if verbose and k == maxiter-1:\n",
    "            print (\"Terminated (maximum number of iterations reached).\")\n",
    "\n",
    "        info = {\"final_objective_value\": L, \"objective_values\": Ls, \"stopping_condition\": stopping_condition,\n",
    "                \"iters\": k+1, \"lams\": lams}\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def _solve_cvx_ccv(self, maxiter=10, tol=1e-5, verbose=False, warm_start=False, **kwargs):\n",
    "        \"\"\"Approximately solves the Problem using the convex-concave procedure.\n",
    "        Parameters\n",
    "        ----------\n",
    "        maxiter : int\n",
    "            Maximum number of iterations (default = 10)\n",
    "        tol : double\n",
    "            Numerical tolerance for stopping condition (default = 1e-5)\n",
    "        verbose : bool\n",
    "            Whether or not to print solver information (default = False)\n",
    "        warm_start : bool\n",
    "            Whether or not to warm start (default = False, which warm starts with un-clipped problem)\n",
    "        **kwargs\n",
    "            Keyword arguments to be sent to cvxpy solve function\n",
    "        Returns\n",
    "        -------\n",
    "        result : objective value\n",
    "        \"\"\"\n",
    "        if not warm_start:\n",
    "            objective = cp.sum([min_expr.expr for min_expr in self.objective.min_exprs])\n",
    "            prob = cp.Problem(cp.Minimize(objective), self.constraints)\n",
    "            prob.solve(**kwargs)\n",
    "\n",
    "        prev_L = float(\"inf\")\n",
    "        for k in range(maxiter):\n",
    "            objective = 0.0\n",
    "            for min_expr in self.objective.min_exprs:\n",
    "                g = max(min_expr.expr.value - min_expr.a, 0.0)\n",
    "                objective += min_expr.expr\n",
    "                objective -= g\n",
    "                if g > 0.0:\n",
    "                    expr_grad = min_expr.expr.grad\n",
    "                    for var in self.vars_:\n",
    "                        if isinstance(expr_grad[var], numbers.Number):\n",
    "                            grad = np.array(expr_grad[var])\n",
    "                        else:\n",
    "                            grad = np.array(expr_grad[var].todense())\n",
    "                        var_minus_prev = var - var.value\n",
    "                        grad = grad.reshape(var_minus_prev.shape)\n",
    "                        objective -= cp.sum(cp.multiply(grad, var_minus_prev))\n",
    "            prob = cp.Problem(cp.Minimize(objective), self.constraints)\n",
    "            result = prob.solve(**kwargs)\n",
    "            L = self.objective.value\n",
    "            if prev_L - L <= tol:\n",
    "                break\n",
    "            prev_L = L\n",
    "            if verbose:\n",
    "                print(\"%04d | %4.8e\" % (k + 1, prev_L))\n",
    "        return L\n",
    "\n",
    "    def _solve_lbfgs(self, warm_start=False, **kwargs):\n",
    "        \"\"\"Use L-BFGS.\"\"\"\n",
    "\n",
    "        if not warm_start:\n",
    "            objective = cp.sum([min_expr.expr for min_expr in self.objective.min_exprs])\n",
    "            prob = cp.Problem(cp.Minimize(objective), self.constraints)\n",
    "            prob.solve()\n",
    "\n",
    "        m = len(self.objective.min_exprs)\n",
    "        n = sum([int(np.prod(v.shape)) for v in self.vars_])\n",
    "\n",
    "        def func(x):\n",
    "            lam = x[:m]\n",
    "            x = x[m:]\n",
    "            unflatten_vars(x, self.vars_)\n",
    "            grad_lam = np.zeros(m)\n",
    "            grad_x = np.zeros(n)\n",
    "            L = 0.0\n",
    "            for i in range(m):\n",
    "                min_expr = self.objective.min_exprs[i]\n",
    "                fi = min_expr.expr.value\n",
    "                ai = min_expr.a\n",
    "                g = flatten_grads(min_expr.expr.grad, self.vars_)\n",
    "                if ai == np.inf:\n",
    "                    grad_x += g\n",
    "                    grad_lam[i] = 0.0\n",
    "                    L += fi\n",
    "                else:\n",
    "                    grad_x += lam[i] * g\n",
    "                    grad_lam[i] = fi - ai\n",
    "                    L += lam[i] * fi + (1 - lam[i]) * ai\n",
    "            grad = np.append(grad_lam, grad_x)\n",
    "\n",
    "            return L, grad\n",
    "\n",
    "        x0 = np.append(.5*np.ones(m), flatten_vars(self.vars_))\n",
    "        bounds = [(0.0, 1.0) for _ in range(m)]\n",
    "        bounds += [(-np.inf, np.inf) for _ in range(n)]\n",
    "\n",
    "        check = check_grad(lambda x: func(x)[0], lambda x: func(x)[1], x0)\n",
    "        assert check <= 1e-4, \"check_grad did not work, %.3f > 1e-4\" % check\n",
    "\n",
    "        result = fmin_l_bfgs_b(func, x0, bounds=bounds, **kwargs)\n",
    "\n",
    "        unflatten_vars(result[0][m:], self.vars_)\n",
    "\n",
    "        return self.objective.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
